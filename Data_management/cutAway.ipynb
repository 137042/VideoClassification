{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import torch\n",
    "\n",
    "video_legal_dir = r\"D:\\Video-Dataset\\2022-NSR-v4-after-3m\\agree\"\n",
    "video_illegal_dir = r\"D:\\Video-Dataset\\2022-NSR-v4-after-3m\\non-agree\"\n",
    "\n",
    "def transform_diagonal(image, mean = 0, std = 0, is_normalize = False):\n",
    "    if is_normalize:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(), \n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "\n",
    "        return transform(image)\n",
    "    else:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(), \n",
    "        ])\n",
    "\n",
    "        return transform(image)\n",
    "\n",
    "def extract_diagnoal_matrix(dir_path : str):\n",
    "    video_paths = glob.glob(dir_path + \"\\*.mp4\")\n",
    "    video_paths.sort()\n",
    "    video_diagonals = []\n",
    "    video_names = []\n",
    "\n",
    "    pre_ht = []\n",
    "\n",
    "    for video_path in tqdm(video_paths, total=len(video_paths), desc=\"Extract Features\"):\n",
    "        vidcap = cv2.VideoCapture(video_path)\n",
    "        vid_total_frames_num = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "        vid_frame_per_s = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
    "        video_name = video_path.split(\"\\\\\")[-1]\n",
    "\n",
    "        sections, retstep = np.linspace(1, vid_total_frames_num, 256, retstep=True)\n",
    "        sections = list(map(math.floor, sections))\n",
    "        frame_diagonals = []\n",
    "        frames = []\n",
    "\n",
    "        while(vidcap.isOpened()):\n",
    "            ret, frame = vidcap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if int(vidcap.get(cv2.CAP_PROP_POS_FRAMES)) in sections:\n",
    "                frame = cv2.resize(frame, (256, 256))\n",
    "\n",
    "                # if int(vidcap.get(cv2.CAP_PROP_POS_FRAMES)) == 1:\n",
    "                #     pre_frame = frame\n",
    "                #     continue\n",
    "                \n",
    "                # frame_df = cv2.absdiff(pre_frame, frame)\n",
    "\n",
    "                frame_r, frame_g, frame_b = frame[:,:,0], frame[:,:,1], frame[:,:,2]\n",
    "                frame_r, frame_g, frame_b = np.diag(frame_r), np.diag(frame_g), np.diag(frame_b)\n",
    "\n",
    "                frame_diagonal = np.stack([frame_r, frame_g, frame_b], -1)\n",
    "                frame_diagonal = np.expand_dims(frame_diagonal, 1)\n",
    "                frame_diagonals.append(frame_diagonal)\n",
    "                # frame_diagonals.append(frame_df)\n",
    "                # pre_frame = frame\n",
    "\n",
    "        vidcap.release()\n",
    "        video_diagonal = np.concatenate(frame_diagonals, axis=1)\n",
    "\n",
    "        # video_diagonal = transform_diagonal(video_diagonal.copy())\n",
    "        # video_diagonal_tr = transform_diagonal(video_diagonal.copy())\n",
    "        # mean, std = video_diagonal_tr.mean([1,2]), video_diagonal_tr.std([1,2])\n",
    "        # video_diagonal = transform_diagonal(video_diagonal, mean, std, True)\n",
    "        # video_diagonal = transform_diagonal(video_diagonal, (0.485, 0.456, 0.406), (0.229, 0.224, 0.225), True)\n",
    "                            \n",
    "        video_diagonals.append(video_diagonal)\n",
    "        video_names.append(video_name)\n",
    "    \n",
    "    return video_names, video_diagonals\n",
    "\n",
    "legal_diagonals = extract_diagnoal_matrix(video_legal_dir)\n",
    "illegal_diagonals = extract_diagnoal_matrix(video_illegal_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagonals_legal = []\n",
    "diagonals_illegal = []\n",
    "legal_names = []\n",
    "illegal_names = []\n",
    "\n",
    "for name, diagonal_legal in zip(legal_diagonals[0], legal_diagonals[1]):\n",
    "    legal_names.append(name)\n",
    "    diagonals_legal.append(diagonal_legal)\n",
    "\n",
    "for name, diagonal_illegal in zip(illegal_diagonals[0], illegal_diagonals[1]):\n",
    "    illegal_names.append(name)\n",
    "    diagonals_illegal.append(diagonal_illegal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, i in zip(illegal_names, diagonals_illegal):\n",
    "    # img_tr = transform_tensor(i)\n",
    "    # mean, std = i.mean([1,2]), i.std([1,2])\n",
    "    # img_nor = i\n",
    "    # i = np.array(i.permute(1, 2, 0))\n",
    "\n",
    "    # print(f\"mean: {mean}, std: {std}\")\n",
    "    # i = i.astype(int)\n",
    "    plt.imshow(i)\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(np.array(i).ravel(), bins=50, density=True)\n",
    "    plt.xlabel(\"pixel values\")\n",
    "    plt.ylabel(\"relative frequency\")\n",
    "    plt.title(\"distribution of pixels\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "save_dir = r\"D:\\Video-Dataset\\v4-image\\non-agree\"\n",
    "\n",
    "def image_save(images):\n",
    "    for name, image in tqdm(zip(images[0], images[1]), total=len(images[0]), desc=\"Image save\"):\n",
    "        name = name.split(\".\")[0] + \".png\"\n",
    "        image = Image.fromarray(image)\n",
    "        image.save(f\"{save_dir}\\{name}\")\n",
    "\n",
    "# image_save(legal_diagonals)\n",
    "image_save(illegal_diagonals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# define custom transform function\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    " \n",
    "# transform the pIL image to tensor\n",
    "# image\n",
    "\n",
    "img_tr = []\n",
    "for i in x:\n",
    "    print(i.shape)\n",
    "    img_tr.append(transform(i))\n",
    "    \n",
    "# Convert tensor image to numpy array\n",
    "\n",
    "img_np = np.array(img_tr[1])\n",
    "\n",
    "# plot the pixel values\n",
    "plt.hist(img_np.ravel(), bins=50, density=True)\n",
    "plt.xlabel(\"pixel values\")\n",
    "plt.ylabel(\"relative frequency\")\n",
    "plt.title(\"distribution of pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "for img in (x):\n",
    "    # img_tr = transform(img)\n",
    "\n",
    "    img_tr = torch.Tensor(img/255.0)\n",
    "    \n",
    "    # calculate mean and std\n",
    "    mean, std = img_tr.mean([1,2]), img_tr.std([1,2])\n",
    "    \n",
    "    # print mean and std\n",
    "    print(\"mean and std before normalize:\")\n",
    "    print(\"Mean of the image:\", mean)\n",
    "    print(\"Std of the image:\", std)\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_norm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "    # transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    " \n",
    "# get normalized image\n",
    "img_normalized = transform_norm(x[0])\n",
    " \n",
    "# convert normalized image to numpy\n",
    "# array\n",
    "img_np = np.array(img_normalized)\n",
    " \n",
    "# plot the pixel values\n",
    "plt.hist(img_np.ravel(), bins=50, density=True)\n",
    "plt.xlabel(\"pixel values\")\n",
    "plt.ylabel(\"relative frequency\")\n",
    "plt.title(\"distribution of pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_nor = transform_norm(x[0])\n",
    " \n",
    "# cailculate mean and std\n",
    "mean, std = img_nor.mean([1,2]), img_nor.std([1,2])\n",
    " \n",
    "# print mean and std\n",
    "print(\"Mean and Std of normalized image:\")\n",
    "print(\"Mean of the image:\", mean)\n",
    "print(\"Std of the image:\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af640ef5e237560663450db179292dda4e36d8af96316b6d53ad8d34500a15be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
