{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import random\n",
    "\n",
    "video_legal_dir = r\"D:\\Video-Dataset\\2022-NSR-3m-재분류\\agree\"\n",
    "video_illegal_dir = r\"D:\\Video-Dataset\\2022-NSR-3m-재분류\\non-agree\"\n",
    "\n",
    "def extract_diagnoal_matrix(dir_path : str):\n",
    "    video_paths = glob.glob(dir_path + \"\\*.mp4\")\n",
    "    random.shuffle(video_paths)\n",
    "    video_paths = video_paths[:5]\n",
    "    video_diagonals = []\n",
    "    video_names = []\n",
    "\n",
    "    pre_ht = []\n",
    "\n",
    "    for video_path in tqdm(video_paths, total=len(video_paths), desc=\"Extract Features\"):\n",
    "        vidcap = cv2.VideoCapture(video_path)\n",
    "        vid_total_frames_num = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "        vid_frame_per_s = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
    "        video_name = video_path.split(\"\\\\\")[-1]\n",
    "\n",
    "        sections, retstep = np.linspace(1, vid_total_frames_num, 257, retstep=True)\n",
    "        sections = list(map(math.floor, sections))\n",
    "        frame_diagonals = []\n",
    "        frames = []\n",
    "\n",
    "        while(vidcap.isOpened()):\n",
    "            ret, frame = vidcap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # if int(vidcap.get(cv2.CAP_PROP_POS_FRAMES)) in sections or int(vidcap.get(cv2.CAP_PROP_POS_FRAMES)) not in sections:\n",
    "            if int(vidcap.get(cv2.CAP_PROP_POS_FRAMES)) in sections:\n",
    "                frame = cv2.resize(frame, (256, 256))\n",
    "\n",
    "                frame_ht = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "                frame_gray_ht = cv2.calcHist(frame_ht, [0], None, [256], [0, 255])\n",
    "                frame_r_ht = cv2.calcHist(frame, [0], None, [256], [0, 255])\n",
    "                frame_g_ht = cv2.calcHist(frame, [1], None, [256], [0, 255])\n",
    "                frame_b_ht = cv2.calcHist(frame, [2], None, [256], [0, 255])\n",
    "\n",
    "                if int(vidcap.get(cv2.CAP_PROP_POS_FRAMES)) == 1:\n",
    "                    pre_frame_r_ht = frame_r_ht\n",
    "                    pre_frame_g_ht = frame_g_ht\n",
    "                    pre_frame_b_ht = frame_b_ht\n",
    "                    continue\n",
    "                \n",
    "                frame_r_ht_df = abs(pre_frame_r_ht - frame_r_ht)\n",
    "                frame_g_ht_df = abs(pre_frame_g_ht - frame_g_ht)\n",
    "                frame_b_ht_df = abs(pre_frame_b_ht - frame_b_ht)\n",
    "\n",
    "                # (256, 256, 3)\n",
    "                frame_diagonal = np.stack([frame_r_ht_df, frame_g_ht_df, frame_b_ht_df], -1)\n",
    "                frame_diagonals.append(frame_diagonal)\n",
    "\n",
    "        vidcap.release()\n",
    "        video_diagonal = np.concatenate(frame_diagonals, axis=1)\n",
    "        # video_diagonal = video_diagonal.astype(float)\n",
    "        # video_diagonal /= (256)\n",
    "        video_diagonals.append(video_diagonal)\n",
    "        video_names.append(video_name)\n",
    "    \n",
    "    return video_names, video_diagonals\n",
    "\n",
    "legal_diagonals = extract_diagnoal_matrix(video_legal_dir)\n",
    "illegal_diagonals = extract_diagnoal_matrix(video_illegal_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagonals_legal = []\n",
    "diagonals_illegal = []\n",
    "legal_names = []\n",
    "illegal_names = []\n",
    "\n",
    "for name, diagonal_legal in zip(legal_diagonals[0], legal_diagonals[1]):\n",
    "    legal_names.append(name)\n",
    "    diagonals_legal.append(diagonal_legal)\n",
    "\n",
    "for name, diagonal_illegal in zip(illegal_diagonals[0], illegal_diagonals[1]):\n",
    "    illegal_names.append(name)\n",
    "    diagonals_illegal.append(diagonal_illegal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, i in zip(legal_names, diagonals_legal):\n",
    "    print(n)\n",
    "    print(i.shape)\n",
    "    # i = i.astype(np.uint8)\n",
    "    plt.imshow(i)\n",
    "    plt.plot\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af640ef5e237560663450db179292dda4e36d8af96316b6d53ad8d34500a15be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
