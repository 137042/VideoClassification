{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = \"다운로드.jpg\"\n",
    "\n",
    "image = np.array(Image.open(path).convert(\"RGB\").resize((256, 256)))\n",
    "image_r, image_g, image_b = image[:,:,0], image[:,:,1], image[:,:,2]\n",
    "image_s = np.stack([image_r, image_g, image_b], -1)\n",
    "image_r, image_g, image_b = np.diag(image_r), np.diag(image_g), np.diag(image_b)\n",
    "\n",
    "# image = plt.imshow(image)\n",
    "# plt.show()\n",
    "\n",
    "# image_s = plt.imshow(image_s)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "\n",
    "video_legal_dir = r\"D:\\Video-Dataset\\2022-NSR-3m-재분류\\agree\"\n",
    "video_illegal_dir = r\"D:\\Video-Dataset\\2022-NSR-3m-재분류\\non-agree\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def extract_diagnoal_matrix(dir_path : str):\n",
    "    video_paths = glob.glob(dir_path + \"\\*\")[:20]\n",
    "    video_paths.sort()\n",
    "    video_diagonals = []\n",
    "    video_names = []\n",
    "\n",
    "    for video_path in tqdm(video_paths, total=len(video_paths), desc=\"Extract Features\"):\n",
    "        vidcap = cv2.VideoCapture(video_path)\n",
    "        vid_total_frames_num = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "        vid_frame_per_s = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "        video_name = video_path.split(\"\\\\\")[-1]\n",
    "\n",
    "        sections, retstep = np.linspace(1, vid_total_frames_num, 256, retstep=True)\n",
    "        sections = list(map(math.floor, sections))\n",
    "        frame_diagonals = []\n",
    "\n",
    "        while(vidcap.isOpened()):\n",
    "            ret, frame = vidcap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            if int(vidcap.get(cv2.CAP_PROP_POS_FRAMES)) in sections:\n",
    "                # frame = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)\n",
    "                frame = cv2.resize(frame, (256, 256))\n",
    "\n",
    "                frame_r, frame_g, frame_b = frame[:,:,0], frame[:,:,1], frame[:,:,2]\n",
    "                frame_r = [[int(np.mean(row))] for row in frame_r]\n",
    "                frame_g = [[int(np.mean(row))] for row in frame_g]\n",
    "                frame_b = [[int(np.mean(row))] for row in frame_b]\n",
    "                # frame_r, frame_g, frame_b = np.diag(frame_r), np.diag(frame_g), np.diag(frame_b)\n",
    "                frame_diagonal = np.stack([frame_r, frame_g, frame_b], -1)\n",
    "                # frame_diagonal = np.expand_dims(frame_diagonal, 1)\n",
    "\n",
    "                frame_diagonals.append(frame_diagonal)\n",
    "        \n",
    "        vidcap.release()\n",
    "        video_diagonal = np.concatenate(frame_diagonals, axis=1)\n",
    "        video_diagonals.append(video_diagonal)\n",
    "        video_names.append(video_name)\n",
    "    \n",
    "    return video_names, video_diagonals\n",
    "\n",
    "legal_diagonals = extract_diagnoal_matrix(video_legal_dir)\n",
    "illegal_diagonals = extract_diagnoal_matrix(video_illegal_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "diagonals_legal = []\n",
    "diagonals_illegal = []\n",
    "for diagonal_legal, diagonal_illegal in zip(legal_diagonals[1], illegal_diagonals[1]):\n",
    "    diagonals_legal.append(diagonal_legal)\n",
    "    diagonals_illegal.append(diagonal_illegal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):    \n",
    "    plt.imshow(diagonals_illegal[i+15])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (0, 1)] [(0, 1), (1, 0)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "a = [(0,1),(0,1),(1,0),(1,0),(1,0),(1,0),(1,0),(1,0),(1,0),(1,0)]\n",
    "\n",
    "x, y = train_test_split(a, test_size=0.2, shuffle=True, random_state=34)\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 2, 0, 5, 3, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "a = [0,1,2,3,4,5]\n",
    "random.shuffle(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(legal_diagonals[1][0])\n",
    "plt.show()\n",
    "\n",
    "# plt.imshow(legal_diagonals[2])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "save_dir = r\"D:\\Video-Dataset\\2022-NSR-3m-재분류\\non-agree-image\"\n",
    "\n",
    "def image_save(images):\n",
    "    for name, image in tqdm(zip(images[0], images[1]), total=len(images[0]), desc=\"Image save\"):\n",
    "        name = name.split(\".\")[0] + \".png\"\n",
    "        image = Image.fromarray(image)\n",
    "        image.save(f\"{save_dir}\\{name}\")\n",
    "\n",
    "# image_save(legal_diagonals)\n",
    "image_save(illegal_diagonals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af640ef5e237560663450db179292dda4e36d8af96316b6d53ad8d34500a15be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
